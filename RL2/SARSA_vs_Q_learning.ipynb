{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SARSA vs Q-learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/islab-ai/AITutorial.git"
      ],
      "metadata": {
        "id": "POptMT-ySUfO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.chdir('/content/AITutorial/RL2')"
      ],
      "metadata": {
        "id": "58un_DS6SeYl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvFnbQ1j8xna",
        "outputId": "f961f27a-2440-49a9-dd46-fe1f5e8d5a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 993 kB of archives.\n",
            "After this operation, 2,982 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 993 kB in 1s (855 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.6)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
            "\u001b[K     |████████████████████████████████| 538 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting EasyProcess\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp37-cp37m-linux_x86_64.whl size=1599499 sha256=19d6b1ba0f7a0061a97924edad6f6c71e7f1a93017cc3fbb7af044526cfa1ad5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/6f/169afb3f2d476c5e807f8515b3c9bc9b819c3962316aa804eb\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: EasyProcess, box2d-py, pyvirtualdisplay, PyOpenGL-accelerate, pygame\n",
            "Successfully installed EasyProcess-1.1 PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 pygame-2.1.2 pyvirtualdisplay-0.2.5\n"
          ]
        }
      ],
      "source": [
        "# install required system dependencies\n",
        "!apt-get install -y xvfb x11-utils\n",
        "# # install required python dependencies (might need to install additional gym extras depending)\n",
        "!pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.* pygame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "import gym\n",
        "from IPython import display as ipythondisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "display = Display(visible=False, size=(400, 300)) # use False with Xvfb\n",
        "_=display.start()"
      ],
      "metadata": {
        "id": "lmFfCcoR813h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the environment \n",
        "env = gym.make(\"CartPole-v1\")\n",
        "# reset the environment before starting\n",
        "env.reset()\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "# loop 10 times\n",
        "for i in range(50):\n",
        "    # take a random action\n",
        "    env.step(env.action_space.sample())\n",
        "    # render the game\n",
        "    screen = env.render(mode='rgb_array')\n",
        "\n",
        "    plt.imshow(screen)\n",
        "    ipythondisplay.clear_output(wait=True)\n",
        "    ipythondisplay.display(plt.gcf())\n",
        "\n",
        "# close the environment\n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "pOyAFZOZ9n5n",
        "outputId": "d6092661-5dcc-4cf8-ecee-1cb629356c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def eps_greedy(Q, s, eps=0.1):\n",
        "    '''\n",
        "    Epsilon greedy policy : 0~1 사이 Epsilon값으로 Action 결정\n",
        "    Epsilon 확률로 Random action 선택,\n",
        "    1-Epsiilon확률로는 최상의 결과를 냈던 Action 선택\n",
        "    '''\n",
        "    if np.random.uniform(0,1) < eps:\n",
        "        # Choose a random action\n",
        "        return np.random.randint(Q.shape[1])\n",
        "    else:\n",
        "        # Choose the action of a greedy policy\n",
        "        return greedy(Q, s)"
      ],
      "metadata": {
        "id": "4clm3sfLAUK1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(Q, s):\n",
        "    '''\n",
        "    Greedy policy : Q function (Action-state value) 값이 가장 높았던 action 선택\n",
        "    '''\n",
        "    return np.argmax(Q[s])"
      ],
      "metadata": {
        "id": "UBkBtbWfAvcd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episodes(env, Q, num_episodes=100, to_print=False):\n",
        "    '''\n",
        "    Run some episodes to test the policy\n",
        "    '''\n",
        "    tot_rew = []\n",
        "    state = env.reset()\n",
        "\n",
        "    for _ in range(num_episodes):\n",
        "        done = False\n",
        "        game_rew = 0\n",
        "\n",
        "        while not done:\n",
        "            # select a greedy action\n",
        "            next_state, rew, done, _ = env.step(greedy(Q, state))\n",
        "\n",
        "            state = next_state\n",
        "            game_rew += rew \n",
        "            if done:\n",
        "                state = env.reset()\n",
        "                tot_rew.append(game_rew)\n",
        "\n",
        "    if to_print:\n",
        "        print('Mean score: %.3f of %i games!'%(np.mean(tot_rew), num_episodes))\n",
        "\n",
        "    return np.mean(tot_rew)"
      ],
      "metadata": {
        "id": "nKoDLwvWAxgV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Q_learning(env, lr=0.01, num_episodes=10000, eps=0.3, gamma=0.95, eps_decay=0.00005):\n",
        "    nA = env.action_space.n\n",
        "    nS = env.observation_space.n\n",
        "\n",
        "    # Initialize the Q matrix\n",
        "    # Q: matrix nS*nA where each row represent a state and each colums represent a different action\n",
        "    Q = np.zeros((nS, nA))\n",
        "    games_reward = []\n",
        "    test_rewards = []\n",
        "\n",
        "    for ep in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        tot_rew = 0\n",
        "        \n",
        "        # decay the epsilon value until it reaches the threshold of 0.01\n",
        "        if eps > 0.01:\n",
        "            eps -= eps_decay\n",
        "\n",
        "        # loop the main body until the environment stops\n",
        "        while not done:\n",
        "            # select an action following the eps-greedy policy\n",
        "            action = eps_greedy(Q, state, eps)\n",
        "\n",
        "            next_state, rew, done, _ = env.step(action) # Take one step in the environment\n",
        "\n",
        "            # Q-learning update the state-action value (get the max Q value for the next state)\n",
        "            Q[state][action] = Q[state][action] + lr*(rew + gamma*np.max(Q[next_state]) - Q[state][action])\n",
        "\n",
        "            state = next_state\n",
        "            tot_rew += rew\n",
        "            if done:\n",
        "                games_reward.append(tot_rew)\n",
        "\n",
        "        # Test the policy every 300 episodes and print the results\n",
        "        if (ep % 300) == 0:\n",
        "            test_rew = run_episodes(env, Q, 1000)\n",
        "            print(\"Episode:{:5d}  Eps:{:2.4f}  Rew:{:2.4f}\".format(ep, eps, test_rew))\n",
        "            test_rewards.append(test_rew)\n",
        "            \n",
        "    return Q\n"
      ],
      "metadata": {
        "id": "iUNFKAVUBCHC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SARSA(env, lr=0.01, num_episodes=10000, eps=0.3, gamma=0.95, eps_decay=0.00005):\n",
        "    nA = env.action_space.n\n",
        "    nS = env.observation_space.n\n",
        "\n",
        "    # Initialize the Q matrix\n",
        "    # Q: matrix nS*nA where each row represent a state and each colums represent a different action\n",
        "    Q = np.zeros((nS, nA))\n",
        "    games_reward = []\n",
        "    test_rewards = []\n",
        "\n",
        "    for ep in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        tot_rew = 0\n",
        "\n",
        "        # decay the epsilon value until it reaches the threshold of 0.01\n",
        "        if eps > 0.01:\n",
        "            eps -= eps_decay\n",
        "\n",
        "\n",
        "        action = eps_greedy(Q, state, eps) \n",
        "\n",
        "        # loop the main body until the environment stops\n",
        "        while not done:\n",
        "            next_state, rew, done, _ = env.step(action) # Take one step in the environment\n",
        "\n",
        "            # choose the next action (needed for the SARSA update)\n",
        "            next_action = eps_greedy(Q, next_state, eps) \n",
        "            # SARSA update\n",
        "            Q[state][action] = Q[state][action] + lr*(rew + gamma*Q[next_state][next_action] - Q[state][action])\n",
        "\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            tot_rew += rew\n",
        "            if done:\n",
        "                games_reward.append(tot_rew)\n",
        "\n",
        "        # Test the policy every 300 episodes and print the results\n",
        "        if (ep % 300) == 0:\n",
        "            test_rew = run_episodes(env, Q, 1000)\n",
        "            print(\"Episode:{:5d}  Eps:{:2.4f}  Rew:{:2.4f}\".format(ep, eps, test_rew))\n",
        "            test_rewards.append(test_rew)\n",
        "\n",
        "    return Q\n"
      ],
      "metadata": {
        "id": "_nZl6UuzBEh7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make('Taxi-v3')\n",
        "    \n",
        "Q_qlearning = Q_learning(env, lr=.1, num_episodes=5000, eps=0.4, gamma=0.95, eps_decay=0.001)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBzcfxBeBFQL",
        "outputId": "f56f9d09-7b56-4bcb-c559-4b0a57e713ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:    0  Eps:0.3990  Rew:-207.2000\n",
            "Episode:  300  Eps:0.0990  Rew:-199.3550\n",
            "Episode:  600  Eps:0.0100  Rew:-178.0340\n",
            "Episode:  900  Eps:0.0100  Rew:-137.0160\n",
            "Episode: 1200  Eps:0.0100  Rew:-87.8180\n",
            "Episode: 1500  Eps:0.0100  Rew:-68.0670\n",
            "Episode: 1800  Eps:0.0100  Rew:-46.4170\n",
            "Episode: 2100  Eps:0.0100  Rew:-22.7670\n",
            "Episode: 2400  Eps:0.0100  Rew:-20.6320\n",
            "Episode: 2700  Eps:0.0100  Rew:2.6060\n",
            "Episode: 3000  Eps:0.0100  Rew:2.2920\n",
            "Episode: 3300  Eps:0.0100  Rew:6.0170\n",
            "Episode: 3600  Eps:0.0100  Rew:6.8730\n",
            "Episode: 3900  Eps:0.0100  Rew:7.9710\n",
            "Episode: 4200  Eps:0.0100  Rew:7.9730\n",
            "Episode: 4500  Eps:0.0100  Rew:7.7440\n",
            "Episode: 4800  Eps:0.0100  Rew:7.7510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_sarsa = SARSA(env, lr=.1, num_episodes=5000, eps=0.4, gamma=0.95, eps_decay=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNdLP6ynKp0d",
        "outputId": "7b7f09fe-453f-4d08-fb95-97105033a7d5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:    0  Eps:0.3990  Rew:-250.2110\n",
            "Episode:  300  Eps:0.0990  Rew:-225.7910\n",
            "Episode:  600  Eps:0.0100  Rew:-181.4820\n",
            "Episode:  900  Eps:0.0100  Rew:-185.2700\n",
            "Episode: 1200  Eps:0.0100  Rew:-119.8860\n",
            "Episode: 1500  Eps:0.0100  Rew:-48.7530\n",
            "Episode: 1800  Eps:0.0100  Rew:-34.2700\n",
            "Episode: 2100  Eps:0.0100  Rew:-42.7040\n",
            "Episode: 2400  Eps:0.0100  Rew:-5.9920\n",
            "Episode: 2700  Eps:0.0100  Rew:-0.2400\n",
            "Episode: 3000  Eps:0.0100  Rew:4.1540\n",
            "Episode: 3300  Eps:0.0100  Rew:4.1200\n",
            "Episode: 3600  Eps:0.0100  Rew:5.6940\n",
            "Episode: 3900  Eps:0.0100  Rew:7.4250\n",
            "Episode: 4200  Eps:0.0100  Rew:7.9170\n",
            "Episode: 4500  Eps:0.0100  Rew:7.9890\n",
            "Episode: 4800  Eps:0.0100  Rew:8.0140\n"
          ]
        }
      ]
    }
  ]
}